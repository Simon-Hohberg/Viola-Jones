{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viola-Jones Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install viola-jones package by running:\n",
    "\n",
    "    pip install -e <path to viola-jones>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import violajones.IntegralImage as ii\n",
    "import violajones.AdaBoost as ab\n",
    "import violajones.Utils as utils\n",
    "from IPython.core.display import Image, display\n",
    "import PIL\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_training_path = 'trainingdata/faces'\n",
    "neg_training_path = 'trainingdata/nonfaces'\n",
    "pos_testing_path = 'trainingdata/faces/test'\n",
    "neg_testing_path = 'trainingdata/nonfaces/test'\n",
    "\n",
    "num_classifiers = 20\n",
    "# For performance reasons restricting feature size\n",
    "min_feature_height = 4\n",
    "max_feature_height = 10\n",
    "min_feature_width = 4\n",
    "max_feature_width = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading faces for training..\n",
      "..done. 127 faces loaded.\n",
      "\n",
      "Loading non faces..\n",
      "..done. 301 non faces loaded.\n",
      "\n",
      "Loading faces for testing..\n",
      "..done. 279 faces loaded.\n",
      "\n",
      "Loading test non faces..\n",
      "..done. 215 non faces loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading faces for training..')\n",
    "faces_training = utils.load_images(pos_training_path)\n",
    "faces_ii_training = list(map(ii.to_integral_image, faces_training))\n",
    "print('..done. ' + str(len(faces_training)) + ' faces loaded.\\n\\nLoading non faces..')\n",
    "non_faces_training = utils.load_images(neg_training_path)\n",
    "non_faces_ii_training = list(map(ii.to_integral_image, non_faces_training))\n",
    "print('..done. ' + str(len(non_faces_training)) + ' non faces loaded.\\n')\n",
    "\n",
    "print('Loading faces for testing..')\n",
    "faces_testing = utils.load_images(pos_testing_path)\n",
    "faces_ii_testing = list(map(ii.to_integral_image, faces_testing))\n",
    "print('..done. ' + str(len(faces_testing)) + ' faces loaded.\\n\\nLoading test non faces..')\n",
    "non_faces_testing = utils.load_images(neg_testing_path)\n",
    "non_faces_ii_testing = list(map(ii.to_integral_image, non_faces_testing))\n",
    "print('..done. ' + str(len(non_faces_testing)) + ' non faces loaded.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn (boost) classifiers (Haar-Like features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating haar-like features..\n",
      "..done. 49122 features created.\n",
      "\n",
      "Calculating scores for images..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (428 of 428) |#######################| Elapsed Time: 0:04:23 Time: 0:04:23\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting classifiers..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |#########################| Elapsed Time: 0:05:08 Time: 0:05:08\n"
     ]
    }
   ],
   "source": [
    "# This will take a while\n",
    "classifiers = ab.learn(faces_ii_training, non_faces_ii_training, num_classifiers, min_feature_height, max_feature_height, min_feature_width, max_feature_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing selected classifiers..\n",
      "..done.\n",
      "\n",
      "Result:\n",
      "      Faces: 242/279  (86.73835125448028%)\n",
      "  non-Faces: 132/215  (61.395348837209305%)\n"
     ]
    }
   ],
   "source": [
    "print('Testing selected classifiers..')\n",
    "correct_faces = 0\n",
    "correct_non_faces = 0\n",
    "correct_faces = sum(utils.ensemble_vote_all(faces_ii_testing, classifiers))\n",
    "correct_non_faces = len(non_faces_testing) - sum(utils.ensemble_vote_all(non_faces_ii_testing, classifiers))\n",
    "\n",
    "print('..done.\\n\\nResult:\\n      Faces: ' + str(correct_faces) + '/' + str(len(faces_testing))\n",
    "      + '  (' + str((float(correct_faces) / len(faces_testing)) * 100) + '%)\\n  non-Faces: '\n",
    "      + str(correct_non_faces) + '/' + str(len(non_faces_testing)) + '  ('\n",
    "      + str((float(correct_non_faces) / len(non_faces_testing)) * 100) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4c7e99725e16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces_ii_testing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                 \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m             \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "reconstruction = utils.reconstruct(classifiers, faces_ii_testing[0].shape)\n",
    "f = io.BytesIO()\n",
    "PIL.Image.fromarray(reconstruction).save(f)\n",
    "display(IPython.display.Image(data=f.getvalue()))\n",
    "display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
